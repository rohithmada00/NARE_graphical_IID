{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install xlrd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs9xYzKTzuD4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.linalg as la\n",
        "from scipy.linalg import solve_sylvester, norm\n",
        "import os\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "import pandas as pd\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MatrixType(Enum):\n",
        "    \"\"\"\n",
        "    Enum representing different available matrices in the data directory\n",
        "    \"\"\"\n",
        "    # SCALE_FREE = \"Scale_Free_Laplacian\"\n",
        "    # ERDOS_RENYI = \"Erdos_Renyi_Laplacian\"\n",
        "    # SMALL_WORLD = \"Small_World_Laplacian\"\n",
        "    # GRID_GRAPH = \"Grid_Graph_Laplacian\"\n",
        "    BUS_33_MODIFIED = \"33bus_modified_ybus\"\n",
        "    WATER_NETWORK = \"water_network\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_B(matrix_type: MatrixType, data_dir='Data'):\n",
        "    \"\"\"\n",
        "    Load a specific matrix from Data directory\n",
        "    \"\"\"\n",
        "    matrix_name = matrix_type.value\n",
        "    file_path = os.path.join(data_dir, matrix_name + '.csv')\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Matrix file '{matrix_name}' not found in {data_dir}.\")\n",
        "\n",
        "    B = pd.read_csv(file_path, header=None).values  # Into a Numpy array\n",
        "\n",
        "    return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.spy(load_B(matrix_type=MatrixType.ERDOS_RENYI))\n",
        "# generate_sparse_covariance(load_B(matrix_type=MatrixType.BUS_33_MODIFIED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tgDmkf5Lg2o"
      },
      "outputs": [],
      "source": [
        "def generate_sparse_covariance(B, sample_scaling=1.0):\n",
        "    \"\"\"\n",
        "    Generate a sparse inverse covariance matrix B, compute its associated covariance matrix E,\n",
        "    and generate samples from a multivariate normal distribution with covariance E.\n",
        "\n",
        "    Parameters:\n",
        "    - n (int): Dimension of the matrix.\n",
        "    - sample_scaling (float): Scaling factor for the number of samples (N = sample_scaling * d^2 log2(n)).\n",
        "    - random_state (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - S (np.ndarray): Sample covariance matrix from the generated samples.\n",
        "    - N (int): Computed number of samples.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(B)\n",
        "\n",
        "    # Mask diagonal of B matrix\n",
        "    B_no_diag = B.copy()\n",
        "    np.fill_diagonal(B_no_diag, 0)\n",
        "\n",
        "    # Now count the number of non-zero elements per row (true degree)\n",
        "    d = np.max(np.sum(B_no_diag != 0, axis=1))\n",
        "    print(\"Max degree in B\", d)\n",
        "\n",
        "    # Compute the required number of samples with log \n",
        "    N = int(sample_scaling * ((d*d) * np.log(n)))\n",
        "\n",
        "    # Compute true inverse covariance matrix (Strue)\n",
        "    Strue = np.linalg.matrix_power(B, 2)\n",
        "\n",
        "    # Compute covariance matrix (E)\n",
        "    E = np.linalg.inv(Strue)\n",
        "\n",
        "    # Generate N samples Y ~ N(0, E)\n",
        "    y_samples = la.sqrtm(E).dot(np.random.randn(n, N))\n",
        "\n",
        "    # Calculate sample covariance matrix\n",
        "    S = np.cov(y_samples)\n",
        "\n",
        "    return S, N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = load_B(MatrixType.GRID_GRAPH)\n",
        "S, N = generate_sparse_covariance(B, sample_scaling=1)\n",
        "plt.subplot(1,3, 1)\n",
        "plt.spy(B)\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.spy(B@B)\n",
        "plt.title(\"True covariance\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.spy(np.linalg.inv(S)>0.1)\n",
        "plt.title(\"Sample covariance\")\n",
        "print(\"Number of samples\", N)\n",
        "print(\"F1 norm\", np.linalg.norm(np.linalg.inv(B@B)-S, ord=\"fro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import schur, solve\n",
        "\n",
        "def sylvester(A, B, Q):\n",
        "    \"\"\"\n",
        "    Solves the Sylvester equation AX + XB = Q\n",
        "    \"\"\"\n",
        "    m, n = Q.shape\n",
        "\n",
        "    # Complex Schur decompositions\n",
        "    A1, U = schur(A, output='complex')\n",
        "    B1, V = schur(B.T, output='complex') \n",
        "    \n",
        "    # Transform Q\n",
        "    Q1 = U.conj().T @ Q @ V\n",
        "\n",
        "    # Initialize solution\n",
        "    X = np.zeros((m, n), dtype=complex)\n",
        "\n",
        "    # Solve column-by-column from right to left\n",
        "    X[:, n-1] = solve(A1 + B1[n-1, n-1] * np.eye(m), Q1[:, n-1])\n",
        "    for i in range(n-2, -1, -1):\n",
        "        v = Q1[:, i] - X[:, i+1:n] @ B1[i, i+1:n].T\n",
        "        X[:, i] = solve(A1 + B1[i, i] * np.eye(m), v)\n",
        "\n",
        "    # Back-transform solution\n",
        "    X = U @ X @ V.T\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQGJnPihlgjt"
      },
      "outputs": [],
      "source": [
        "def newton_nare(A, B, C, D, X0, tol=1e-13, kmax=30):\n",
        "    \"\"\"\n",
        "    Newton's method for solving the Nonlinear Algebraic Riccati Equation (NARE):\n",
        "    C + XA + DX - XBX = 0\n",
        "    \"\"\"\n",
        "    X = X0.copy()\n",
        "    k = 0\n",
        "    err = 1\n",
        "\n",
        "    while err > tol and k < kmax:\n",
        "        # Compute residual RX = C + XA + DX - XBX\n",
        "        RX = C + X @ A + D @ X - X @ B @ X\n",
        "\n",
        "        # Solve the Sylvester equation (D - XB)H + H(A - BX) = -RX for H\n",
        "        H = solve_sylvester(D - X @ B, A - B @ X, -RX)\n",
        "\n",
        "        # Update X\n",
        "        X = X + H\n",
        "\n",
        "        # Calculate the error; changed from l1 to frobenius\n",
        "        err = norm(H, 1) / norm(X, 1)\n",
        "        # err = norm(H, 'fro') / (1 + norm(X, 'fro'))\n",
        "\n",
        "        if k % 5 == 0:  # Print every 5 iterations\n",
        "            print(f\"Iteration {k}, Error: {err:.2e}\")\n",
        "        \n",
        "        # Increment iteration counter\n",
        "        k += 1\n",
        "\n",
        "    # Check if the solution converged\n",
        "    if k == kmax:\n",
        "        print(\"Warning: reached the maximum number of iterations without convergence.\")\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdGMJuRwnPup"
      },
      "outputs": [],
      "source": [
        "# Soft thresholding function\n",
        "def soft_thresholding(x, threshold):\n",
        "    \"\"\"Applies soft-thresholding elementwise.\"\"\"\n",
        "    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def soft_thresholding_offdiag(B_new, Lambda, lambda_, rho):\n",
        "    \"\"\"\n",
        "    Applies off-diagonal soft-thresholding.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute argument for soft-thresholding\n",
        "    X = rho * B_new + Lambda\n",
        "    \n",
        "    # Create a copy to modify\n",
        "    Z_new = X.copy()\n",
        "    \n",
        "    # Off-diagonal mask\n",
        "    mask_offdiag = ~np.eye(X.shape[0], dtype=bool)\n",
        "\n",
        "    # Apply soft-thresholding only to off-diagonal elements\n",
        "    Z_new[mask_offdiag] = np.sign(X[mask_offdiag]) * np.maximum(np.abs(X[mask_offdiag]) - lambda_, 0)\n",
        "\n",
        "    return Z_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2vCOGBFnT5J"
      },
      "outputs": [],
      "source": [
        "# ADMM Algorithm for Elastic-Net Penalized Precision Matrix Estimation\n",
        "def admm_precision_matrix(S, lambda_, rho=1.0, max_iter=100, tol=1e-4):\n",
        "    \"\"\"\n",
        "    ADMM algorithm for precision matrix estimation with elastic-net penalty.\n",
        "    \"\"\"\n",
        "    n = S.shape[0]\n",
        "    Z = np.zeros((n, n))\n",
        "    Lambda = np.zeros((n, n))\n",
        "    I = np.eye(n)  # Identity matrix\n",
        "\n",
        "    # Initial B (can be initialized as identity matrix)\n",
        "    B = np.eye(n)\n",
        "\n",
        "    for k in range(max_iter):\n",
        "        # Step 1: Update B using Newton NARE\n",
        "        # Here, we set up the matrices to solve the NARE: A3 + XA1 + A4X - XA2X = 0\n",
        "        A3 = - 2 * I\n",
        "        A4 = Lambda - rho * Z\n",
        "        A1 = 0 * I\n",
        "        A2 = - (2 * S + rho * I)\n",
        "        X0 = B  # Initial guess for Newton NARE\n",
        "\n",
        "        # Solve for the new B using Newton NARE\n",
        "        B_new = newton_nare(A1, A2, A3, A4, X0)\n",
        "\n",
        "        # Step 2: Update Z elementwise using soft-thresholding\n",
        "        Z_new = soft_thresholding(rho * B_new + Lambda, lambda_)\n",
        "        Z_new = Z_new / rho\n",
        "\n",
        "        # Step 3: Update Lambda (Lagrange multiplier)\n",
        "        Lambda_new = Lambda + rho * (B_new - Z_new)\n",
        "\n",
        "        # print(f\"ADMM update loss: \", np.linalg.norm(B_new - B, ord='fro') )\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(B_new - B, ord='fro') < tol:\n",
        "            print(f\"ADMM Converged after {k+1} iterations.\")\n",
        "            break\n",
        "        elif k == max_iter-1 :\n",
        "            print(f\"ADMM failed to converge after {k+1} iterations.\")\n",
        "\n",
        "        # Update for the next iteration\n",
        "        B, Z, Lambda = B_new, Z_new, Lambda_new      \n",
        "\n",
        "    return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0IvvFLPs1u-"
      },
      "outputs": [],
      "source": [
        "#Thresholding B_estimate\n",
        "def hard_threshold(B_estimate,threshold):\n",
        "  return np.where(np.abs(B_estimate) > threshold, B_estimate, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = load_B(matrix_type=MatrixType.ERDOS_RENYI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S, N = generate_sparse_covariance(B, sample_scaling=1.0)\n",
        "# Parameters for the elastic-net penalty and ADMM algorithm\n",
        "lambda_ = 0.166  # Regularization strength\n",
        "alpha = 1  # Mixing parameter (0 = Ridge, 1 = Lasso)\n",
        "rho = 1.0  # ADMM penalty parameter\n",
        "max_iter = 200  # Maximum number of iterations\n",
        "tol = 1e-4  # Convergence tolerance\n",
        "\n",
        "# Run the ADMM algorithm using the generated sample covariance matrix\n",
        "B_estimate = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "\n",
        "print(\"Estimated Precision Matrix (B estimate):\")\n",
        "print(B_estimate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.subplot(1,3, 1)\n",
        "plt.spy(B)\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "# plt.imshow(hard_threshold(B_estimate, 0.2), cmap= \"gray\")\n",
        "plt.spy(hard_threshold(B_estimate, 0.1))\n",
        "plt.title(\"B estimate - 0.1 tres\")\n",
        "plt.subplot(1,3,3)\n",
        "# plt.imshow(hard_threshold(B_estimate, 0.4), cmap= \"gray\")\n",
        "plt.spy(hard_threshold(B_estimate, 1e-2))\n",
        "plt.tight_layout()\n",
        "plt.title(\"B estimate - 1e-2 tres\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_f1_vs_lambda(\n",
        "        lambda_values, B, sample_scaling=1.0,\n",
        "        rho=1.0, max_iter=100, tol=1e-4,\n",
        "        threshold=1e-4, save_plots = False, log_dir=\"experiment_logs\"):\n",
        "    \"\"\"\n",
        "    Evaluate f1 scores, \n",
        "    excluding diagonal elements, for each lambda.\n",
        "    \"\"\"\n",
        "    \n",
        "    B = np.array(B)\n",
        "    n = B.shape[0]\n",
        "    \n",
        "    # Generate sample covariance S and sample size N\n",
        "    S, N = generate_sparse_covariance(B, sample_scaling=sample_scaling)\n",
        "\n",
        "    print(\"Number of samples:\", N)\n",
        "    print(\"Minimum eigenvalue of B:\", np.min(np.linalg.eigvals(B)))\n",
        "\n",
        "    # Ground-truth adjacency (full)\n",
        "    ground_truth_adjacency = (B != 0).astype(int)\n",
        "\n",
        "    # Exclude diagonals via a mask\n",
        "    mask_offdiag = ~np.eye(n, dtype=bool)\n",
        "\n",
        "    metrics = {\n",
        "        \"lambda\": [],\n",
        "        \"f1\": [],\n",
        "    }\n",
        "\n",
        "    for lambda_ in lambda_values:\n",
        "        # Estimate precision matrix with user-defined ADMM function\n",
        "        B_est = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "\n",
        "        # Threshold the estimate\n",
        "        B_est_thresholded = hard_threshold(B_est, threshold)\n",
        "\n",
        "        if save_plots:\n",
        "            # Plot and save the sparsity patterns (optional, can remove if not needed)\n",
        "            plt.figure(figsize=(6, 12))\n",
        "            \n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.spy(B)\n",
        "            plt.title(\"B (True)\", fontsize=16)\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.spy(B_est_thresholded)\n",
        "            plt.title(\"B_est (Estimated)\", fontsize=16)\n",
        "\n",
        "            plot_path = os.path.join(log_dir, f\"sparsity_lambda_{lambda_:.3f}.png\")\n",
        "            plt.savefig(plot_path)\n",
        "            plt.close()\n",
        "            \n",
        "        \n",
        "        predicted_adjacency = (B_est_thresholded != 0).astype(int)\n",
        "        gt_offdiag = ground_truth_adjacency[mask_offdiag]\n",
        "        pred_offdiag = predicted_adjacency[mask_offdiag]\n",
        "\n",
        "        f1 = f1_score(gt_offdiag, pred_offdiag)\n",
        "\n",
        "        # Store the results\n",
        "        metrics[\"lambda\"].append(lambda_)\n",
        "        metrics[\"f1\"].append(f1)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V2nbZQbUthdT",
        "outputId": "b5159b66-0f83-4b92-92f9-3cf7caa3c334"
      },
      "outputs": [],
      "source": [
        "# Updated main loop\n",
        "sample_scaling = 2\n",
        "matrix_type = MatrixType.WATER_NETWORK\n",
        "B = load_B(matrix_type)\n",
        "\n",
        "log_dir = f\"experiment_logs/{matrix_type._value_}/{sample_scaling}\"\n",
        "# Create a directory to save logs if it doesn’t exist\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# params\n",
        "args = {\n",
        "    \"lambda_values\": np.linspace(0,0.3, 30).tolist(),\n",
        "    \"B\": B.tolist(),\n",
        "    \"sample_scaling\": sample_scaling,\n",
        "    \"rho\": 2.0,\n",
        "    \"max_iter\": 200,\n",
        "    \"tol\": 1e-4,\n",
        "    \"threshold\": 1e-1,\n",
        "    \"log_dir\": log_dir, \n",
        "    \"save_plots\": True\n",
        "}\n",
        "print(f\"Evaluating metrics for {args}\")\n",
        "\n",
        "# Save args to a JSON file (for reproducibility)\n",
        "json_path = os.path.join(log_dir, \"params.json\")\n",
        "with open(json_path, \"w\") as json_file:\n",
        "    json.dump(args, json_file, indent=4)\n",
        "\n",
        "# Call our updated evaluate_metrics_vs_lambda\n",
        "metrics = evaluate_f1_vs_lambda(**args)\n",
        "\n",
        "# Convert metrics to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Save metrics to CSV or Excel\n",
        "csv_path = os.path.join(log_dir, \"metrics.csv\")\n",
        "metrics_df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Pick best lambda by F1\n",
        "best_idx = metrics_df[\"f1\"].idxmax()\n",
        "best_f1 = metrics_df[\"f1\"].max()\n",
        "best_lambda = metrics_df.loc[best_idx, \"lambda\"]\n",
        "print(f\"Best f1 scores = {best_f1}\")\n",
        "print(f\"Best lambda by f1 = {best_lambda:.3f}\")\n",
        "\n",
        "# Plot all metrics vs. lambda\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(metrics_df[\"lambda\"], metrics_df[\"f1\"])\n",
        "\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"F1 score\")\n",
        "plt.title(\"Metrics vs. F1\")\n",
        "plt.legend()\n",
        "plot_path = os.path.join(log_dir, \"f1_vs_lambda.png\")\n",
        "plt.savefig(plot_path)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 vs scaling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams.update({\n",
        "    \"text.usetex\": False,          # Turn off external LaTeX\n",
        "    \"font.family\": \"serif\",        # Use serif fonts like Times\n",
        "    \"font.serif\": [\"Times New Roman\", \"Times\"],\n",
        "    \"axes.labelsize\": 14,\n",
        "    \"font.size\": 13,\n",
        "    \"legend.fontsize\": 12,\n",
        "    \"xtick.labelsize\": 12,\n",
        "    \"ytick.labelsize\": 12\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_f1_vs_sample_scaling(\n",
        "    best_lambda=0.1655,\n",
        "    rho=4.0,\n",
        "    max_iter=200,\n",
        "    tol=1e-4,\n",
        "    threshold=1e-1,\n",
        "    scaling_values=[0.1, 0.5, 1, 1.5, 2, 5, 10, 15],\n",
        "    num_trials=1,\n",
        "    log_dir=\"experiment_scale_logs\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Fix parameters (n, alpha, best_lambda, etc.) and update sample_scaling from\n",
        "    to see how F1 improves with more samples for different d values\n",
        "    \"\"\"    \n",
        "    \n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n",
        "    \n",
        "    results_f1 = []\n",
        "    results_error = []\n",
        "\n",
        "    markers = {\n",
        "        # MatrixType.GRID_GRAPH: \"o\",\n",
        "        # MatrixType.SMALL_WORLD: \"s\",\n",
        "        # MatrixType.SCALE_FREE: \"D\",\n",
        "        # MatrixType.ERDOS_RENYI: \"^\"\n",
        "        MatrixType.BUS_33_MODIFIED: \"o\",\n",
        "        MatrixType.WATER_NETWORK: \"^\"\n",
        "    }\n",
        "    linestyles = {\n",
        "        # MatrixType.GRID_GRAPH: \"dashed\",\n",
        "        # MatrixType.SMALL_WORLD: \"dashdot\",\n",
        "        # MatrixType.SCALE_FREE: \"dotted\",\n",
        "        # MatrixType.ERDOS_RENYI: \"solid\"\n",
        "        MatrixType.BUS_33_MODIFIED: \"dashed\",\n",
        "        MatrixType.WATER_NETWORK: \"dashdot\",\n",
        "    }\n",
        "    \n",
        "    for matrix_type in MatrixType:\n",
        "        f1_scores = []\n",
        "        worst_case_errors = []\n",
        "        B = load_B(matrix_type)\n",
        "\n",
        "         # Ground-truth adjacency (full)\n",
        "        ground_truth_adjacency = (B != 0).astype(int)\n",
        "        # Exclude diagonals via a mask\n",
        "        mask_offdiag = ~np.eye(len(B), dtype=bool)\n",
        "        \n",
        "        for scale in scaling_values:\n",
        "            _f1_scores = []\n",
        "            _max_errors = []\n",
        "            for _ in range(num_trials):\n",
        "                # Generate data with the current scale\n",
        "                S, N = generate_sparse_covariance(B, sample_scaling=scale)\n",
        "                \n",
        "                # Estimate precision matrix using the best param config\n",
        "                B_est = admm_precision_matrix(S, best_lambda, rho, max_iter, tol)\n",
        "                \n",
        "                # Threshold the estimate\n",
        "                B_est_thresholded = hard_threshold(B_est, threshold)\n",
        "                \n",
        "                predicted_adjacency = (B_est_thresholded != 0).astype(int)\n",
        "                gt_offdiag = ground_truth_adjacency[mask_offdiag]\n",
        "                pred_offdiag = predicted_adjacency[mask_offdiag]\n",
        "\n",
        "                f1 = f1_score(gt_offdiag, pred_offdiag)\n",
        "                _f1_scores.append(f1)\n",
        "                # Compute absolute difference matrix\n",
        "                abs_diff = np.abs(B_est - B)\n",
        "                # Mask diagonal values\n",
        "                offdiag_diff = abs_diff[mask_offdiag]\n",
        "                # L-infinity norm over off-diagonal entries\n",
        "                max_error = np.max(offdiag_diff)\n",
        "                _max_errors.append(max_error)\n",
        "            \n",
        "            f1_scores.append(np.mean(_f1_scores))\n",
        "            worst_case_errors.append(np.mean(_max_errors))\n",
        "            print(f\"scale={scale}, #samples={N}, F1={np.average(_f1_scores):.3f}\")\n",
        "        \n",
        "        # results_f1.append(pd.DataFrame({\"sample_scaling\": scaling_values, \"F1\": f1_scores}))\n",
        "        # results_error.append(pd.DataFrame({\"sample_scaling\": scaling_values, \"Error\": worst_case_errors}))\n",
        "        axs[0].plot(scaling_values, f1_scores, label=matrix_type.name, marker=markers[matrix_type], linestyle=linestyles[matrix_type])\n",
        "        axs[1].plot(scaling_values, worst_case_errors, label=matrix_type.name, marker=markers[matrix_type], linestyle=linestyles[matrix_type])\n",
        "    \n",
        "    # df = pd.concat(results, ignore_index=True)\n",
        "    # Save to CSV\n",
        "    # csv_path = os.path.join(log_dir, f\"f1_vs_scaling_threshold_{threshold}.csv\")\n",
        "    # df.to_csv(csv_path, index=False)\n",
        "    \n",
        "    # Plot\n",
        "    axs[0].set_xlabel(r\"$n/(d^2 \\log p)$\", fontsize=13)\n",
        "    axs[0].set_ylabel(\"Average F-score\", fontsize=13)\n",
        "    # axs[0].set_title(\"Average F-score\", fontsize=14)\n",
        "    axs[0].legend(fontsize=11)\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    axs[1].set_xlabel(r\"$n/(d^2 \\log p)$\", fontsize=13)\n",
        "    axs[1].set_ylabel(r\"$\\left\\|\\hat{\\Delta}_B - \\Delta_B^*\\right\\|_{\\infty}$\", fontsize=13)\n",
        "    # axs[1].set_title(\"Worst case error bound\", fontsize=14)\n",
        "    axs[1].grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_f1_vs_sample_scaling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
