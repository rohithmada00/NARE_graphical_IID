{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs9xYzKTzuD4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.linalg as la\n",
        "from scipy.linalg import solve_sylvester, norm\n",
        "import os\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "import pandas as pd\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MatrixType(Enum):\n",
        "    \"\"\"\n",
        "    Enum representing different available matrices in the data directory\n",
        "    \"\"\"\n",
        "    SCALE_FREE = \"Scale_Free_Laplacian\"\n",
        "    ERDOS_RENYI = \"Erdos_Renyi_Laplacian\"\n",
        "    SMALL_WORLD = \"Small_World_Laplacian\"\n",
        "    GRID_GRAPH = \"Grid_Graph_Laplacian\"\n",
        "    BUS_33_MODIFIED = \"33bus_modified_ybus_binary\"\n",
        "    WATER_NETWORK = \"water_network\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_positive_definite(M, epsilon=1, min_threshold=1e-3):\n",
        "    \"\"\"\n",
        "    Ensure M is well-conditioned ; add small value to diagonal if needed\n",
        "    \"\"\"\n",
        "    min_eig = np.min(np.linalg.eigvals(M))\n",
        "    \n",
        "    if min_eig < min_threshold:\n",
        "        print(f\"Minimum eigenvalue too small ({min_eig:.2e}), adding {epsilon} to diagonal elements.\")\n",
        "        M += np.eye(M.shape[0]) * (abs(min_eig) + epsilon)\n",
        "    \n",
        "    return M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_B(matrix_type: MatrixType, data_dir='Data'):\n",
        "    \"\"\"\n",
        "    Load a specific matrix from Data directory\n",
        "    \"\"\"\n",
        "    matrix_name = matrix_type.value\n",
        "    file_path = os.path.join(data_dir, matrix_name + '.csv')\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Matrix file '{matrix_name}' not found in {data_dir}.\")\n",
        "\n",
        "    B = pd.read_csv(file_path, header=None).values  # into a numpy array\n",
        "    \n",
        "    return ensure_positive_definite(B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for matrix_type in MatrixType:\n",
        "    B = load_B(matrix_type)\n",
        "    print(f'Is {matrix_type.value} symmetric: {la.issymmetric(B)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tgDmkf5Lg2o"
      },
      "outputs": [],
      "source": [
        "def generate_sparse_covariance(B, sample_scaling=1.0):\n",
        "    \"\"\"\n",
        "    Generate a sparse inverse covariance matrix B, compute its associated covariance matrix E,\n",
        "    and generate samples from a multivariate normal distribution with covariance E.\n",
        "\n",
        "    Parameters:\n",
        "    - n (int): Dimension of the matrix.\n",
        "    - sample_scaling (float): Scaling factor for the number of samples (N = sample_scaling * d^2 log2(n)).\n",
        "    - random_state (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - S (np.ndarray): Sample covariance matrix from the generated samples.\n",
        "    - N (int): Computed number of samples.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(B)\n",
        "\n",
        "    # Mask diagonal of B matrix\n",
        "    B_no_diag = B.copy()\n",
        "    np.fill_diagonal(B_no_diag, 0)\n",
        "\n",
        "    # Now count the number of non-zero elements per row (true degree)\n",
        "    d = np.max(np.sum(B_no_diag != 0, axis=1))\n",
        "    print(\"Max degree in B\", d)\n",
        "\n",
        "    # Compute the required number of samples with log \n",
        "    N = int(sample_scaling * ((d*d) * np.log(n)))\n",
        "\n",
        "    # Compute true inverse covariance matrix (Strue)\n",
        "    Strue = np.linalg.matrix_power(B, 2)\n",
        "\n",
        "    # Compute covariance matrix (E)\n",
        "    E = np.linalg.inv(Strue)\n",
        "\n",
        "    # Generate N samples Y ~ N(0, E)\n",
        "    y_samples = la.sqrtm(E).dot(np.random.randn(n, N))\n",
        "\n",
        "    # Calculate sample covariance matrix\n",
        "    S = np.cov(y_samples)\n",
        "\n",
        "    return S, N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = load_B(MatrixType.BUS_33_MODIFIED)\n",
        "S, N = generate_sparse_covariance(B, sample_scaling=1)\n",
        "plt.subplot(1,3, 1)\n",
        "plt.spy(B)\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.spy(B@B)\n",
        "plt.title(\"True covariance\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.spy(np.linalg.inv(S)>0.1)\n",
        "plt.title(\"Sample covariance\")\n",
        "print(\"Number of samples\", N)\n",
        "print(\"F1 norm\", np.linalg.norm(np.linalg.inv(B@B)-S, ord=\"fro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQGJnPihlgjt"
      },
      "outputs": [],
      "source": [
        "def newton_nare(A, B, C, D, X0, tol=1e-13, kmax=30):\n",
        "    \"\"\"\n",
        "    Newton's method for solving the Nonlinear Algebraic Riccati Equation (NARE):\n",
        "    C + XA + DX - XBX = 0\n",
        "    \"\"\"\n",
        "    X = X0.copy()\n",
        "    k = 0\n",
        "    err = 1\n",
        "\n",
        "    while err > tol and k < kmax:\n",
        "        # Compute residual RX = C + XA + DX - XBX\n",
        "        RX = C + X @ A + D @ X - X @ B @ X\n",
        "\n",
        "        # Solve the Sylvester equation (D - XB)H + H(A - BX) = -RX for H\n",
        "        H = solve_sylvester(D - X @ B, A - B @ X, -RX)\n",
        "\n",
        "        # Update X\n",
        "        X = X + H\n",
        "\n",
        "        # Calculate the error; changed from l1 to frobenius\n",
        "        err = norm(H, 1) / norm(X, 1)\n",
        "        # err = norm(H, 'fro') / (1 + norm(X, 'fro'))\n",
        "\n",
        "        if k % 5 == 0:  # Print every 5 iterations\n",
        "            print(f\"Iteration {k}, Error: {err:.2e}\")\n",
        "        \n",
        "        # Increment iteration counter\n",
        "        k += 1\n",
        "\n",
        "    # Check if the solution converged\n",
        "    if k == kmax:\n",
        "        print(\"Warning: reached the maximum number of iterations without convergence.\")\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def soft_thresholding_offdiag(B_new, Lambda, lambda_, rho):\n",
        "    \"\"\"\n",
        "    Applies off-diagonal soft-thresholding.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute argument for soft-thresholding\n",
        "    X = rho * B_new + Lambda\n",
        "    \n",
        "    # Create a copy to modify\n",
        "    Z_new = X.copy()\n",
        "    \n",
        "    # Off-diagonal mask\n",
        "    mask_offdiag = ~np.eye(X.shape[0], dtype=bool)\n",
        "\n",
        "    # Apply soft-thresholding only to off-diagonal elements\n",
        "    Z_new[mask_offdiag] = np.sign(X[mask_offdiag]) * np.maximum(np.abs(X[mask_offdiag]) - lambda_, 0)\n",
        "\n",
        "    return Z_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2vCOGBFnT5J"
      },
      "outputs": [],
      "source": [
        "# ADMM Algorithm for Elastic-Net Penalized Precision Matrix Estimation\n",
        "def admm_precision_matrix(S, lambda_, rho=1.0, max_iter=100, tol=1e-4):\n",
        "    \"\"\"\n",
        "    ADMM algorithm for precision matrix estimation with elastic-net penalty.\n",
        "    \"\"\"\n",
        "    n = S.shape[0]\n",
        "    Z = np.zeros((n, n))\n",
        "    Lambda = np.zeros((n, n))\n",
        "    I = np.eye(n)  # Identity matrix\n",
        "\n",
        "    # Initial B (can be initialized as identity matrix)\n",
        "    B = np.eye(n)\n",
        "\n",
        "    for k in range(max_iter):\n",
        "        # Step 1: Update B using Newton NARE\n",
        "        # Here, we set up the matrices to solve the NARE: A3 + XA1 + A4X - XA2X = 0\n",
        "        A3 = - 2 * I\n",
        "        A4 = Lambda - rho * Z\n",
        "        A1 = 0 * I\n",
        "        A2 = - (2 * S + rho * I)\n",
        "        X0 = B  # Initial guess for Newton NARE\n",
        "\n",
        "        # Solve for the new B using Newton NARE\n",
        "        B_new = newton_nare(A1, A2, A3, A4, X0)\n",
        "\n",
        "        # Step 2: Update Z elementwise using soft-thresholding\n",
        "        # Z_new = soft_thresholding(rho * B_new + Lambda, lambda_)\n",
        "        Z_new = soft_thresholding_offdiag(B_new, Lambda, lambda_, rho)\n",
        "        Z_new = Z_new / rho\n",
        "\n",
        "        # Step 3: Update Lambda (Lagrange multiplier)\n",
        "        Lambda_new = Lambda + rho * (B_new - Z_new)\n",
        "\n",
        "        # print(f\"ADMM update loss: \", np.linalg.norm(B_new - B, ord='fro') )\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(B_new - B, ord='fro') < tol:\n",
        "            print(f\"ADMM Converged after {k+1} iterations.\")\n",
        "            break\n",
        "        elif k == max_iter-1 :\n",
        "            print(f\"ADMM failed to converge after {k+1} iterations.\")\n",
        "\n",
        "        # Update for the next iteration\n",
        "        B, Z, Lambda = B_new, Z_new, Lambda_new      \n",
        "\n",
        "    return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0IvvFLPs1u-"
      },
      "outputs": [],
      "source": [
        "#Thresholding B_estimate\n",
        "def hard_threshold(B_estimate,threshold):\n",
        "  return np.where(np.abs(B_estimate) > threshold, B_estimate, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B = load_B(matrix_type=MatrixType.BUS_33_MODIFIED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "S, N = generate_sparse_covariance(B, sample_scaling=2)\n",
        "\n",
        "print(f'Number of samples used: {N}')\n",
        "# Parameters for the elastic-net penalty and ADMM algorithm\n",
        "lambda_ = 0.1  # Regularization strength\n",
        "rho = 1.0  # ADMM penalty parameter\n",
        "max_iter = 200  # Maximum number of iterations\n",
        "tol = 1e-5  # Convergence tolerance\n",
        "\n",
        "# Run the ADMM algorithm using the generated sample covariance matrix\n",
        "B_estimate = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "\n",
        "print(\"Estimated Precision Matrix (B estimate):\")\n",
        "print(B_estimate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.subplot(1,3, 1)\n",
        "plt.spy(B)\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "# plt.imshow(hard_threshold(B_estimate, 0.2), cmap= \"gray\")\n",
        "plt.spy(hard_threshold(B_estimate, 0.4))\n",
        "plt.title(\"B estimate - 0.1 tres\")\n",
        "plt.subplot(1,3,3)\n",
        "# plt.imshow(hard_threshold(B_estimate, 0.4), cmap= \"gray\")\n",
        "plt.spy(hard_threshold(B_estimate, 1e-2))\n",
        "plt.tight_layout()\n",
        "plt.title(\"B estimate - 1e-2 tres\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_f1_vs_lambda(\n",
        "        lambda_values, B, sample_scaling=1.0,\n",
        "        rho=1.0, max_iter=100, tol=1e-4,\n",
        "        threshold=1e-4, save_plots = False, log_dir=\"experiment_logs\"):\n",
        "    \"\"\"\n",
        "    Evaluate f1 scores, \n",
        "    excluding diagonal elements, for each lambda.\n",
        "    \"\"\"\n",
        "    \n",
        "    B = np.array(B)\n",
        "    n = B.shape[0]\n",
        "    \n",
        "    # Generate sample covariance S and sample size N\n",
        "    S, N = generate_sparse_covariance(B, sample_scaling=sample_scaling)\n",
        "\n",
        "    print(\"Number of samples:\", N)\n",
        "    print(\"Minimum eigenvalue of B:\", np.min(np.linalg.eigvals(B)))\n",
        "\n",
        "    # Ground-truth adjacency (full)\n",
        "    ground_truth_adjacency = (B != 0).astype(int)\n",
        "\n",
        "    # Exclude diagonals via a mask\n",
        "    mask_offdiag = ~np.eye(n, dtype=bool)\n",
        "\n",
        "    metrics = {\n",
        "        \"lambda\": [],\n",
        "        \"f1\": [],\n",
        "    }\n",
        "\n",
        "    for lambda_ in lambda_values:\n",
        "        # Estimate precision matrix with user-defined ADMM function\n",
        "        B_est = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "\n",
        "        # Threshold the estimate\n",
        "        B_est_thresholded = hard_threshold(B_est, threshold)\n",
        "\n",
        "        if save_plots:\n",
        "            # Plot and save the sparsity patterns (optional, can remove if not needed)\n",
        "            plt.figure(figsize=(6, 12))\n",
        "            \n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.spy(B)\n",
        "            plt.title(\"B (True)\", fontsize=16)\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.spy(B_est_thresholded)\n",
        "            plt.title(\"B_est (Estimated)\", fontsize=16)\n",
        "\n",
        "            plot_path = os.path.join(log_dir, f\"sparsity_lambda_{lambda_:.3f}.png\")\n",
        "            plt.savefig(plot_path)\n",
        "            plt.close()\n",
        "            \n",
        "        \n",
        "        predicted_adjacency = (B_est_thresholded != 0).astype(int)\n",
        "        gt_offdiag = ground_truth_adjacency[mask_offdiag]\n",
        "        pred_offdiag = predicted_adjacency[mask_offdiag]\n",
        "\n",
        "        f1 = f1_score(gt_offdiag, pred_offdiag)\n",
        "\n",
        "        # Store the results\n",
        "        metrics[\"lambda\"].append(lambda_)\n",
        "        metrics[\"f1\"].append(f1)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V2nbZQbUthdT",
        "outputId": "b5159b66-0f83-4b92-92f9-3cf7caa3c334"
      },
      "outputs": [],
      "source": [
        "# Updated main loop\n",
        "sample_scaling = 3\n",
        "matrix_type = MatrixType.BUS_33_MODIFIED\n",
        "B = load_B(matrix_type)\n",
        "print(f'Is B pd: {np.min(np.linalg.eigvals(B))>0}')\n",
        "\n",
        "log_dir = f\"experiment_logs/{matrix_type._value_}/{sample_scaling}\"\n",
        "# Create a directory to save logs if it doesn’t exist\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# params\n",
        "args = {\n",
        "    \"lambda_values\": np.linspace(0,0.5, 10).tolist(),\n",
        "    \"B\": B.tolist(),\n",
        "    \"sample_scaling\": sample_scaling,\n",
        "    \"rho\": 1.0,\n",
        "    \"max_iter\": 200,\n",
        "    \"tol\": 1e-4,\n",
        "    \"threshold\": 1e-1,\n",
        "    \"log_dir\": log_dir, \n",
        "    \"save_plots\": True\n",
        "}\n",
        "print(f\"Evaluating metrics for {args}\")\n",
        "\n",
        "# Save args to a JSON file (for reproducibility)\n",
        "json_path = os.path.join(log_dir, \"params.json\")\n",
        "with open(json_path, \"w\") as json_file:\n",
        "    json.dump(args, json_file, indent=4)\n",
        "\n",
        "# Call our updated evaluate_metrics_vs_lambda\n",
        "metrics = evaluate_f1_vs_lambda(**args)\n",
        "\n",
        "# Convert metrics to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Save metrics to CSV or Excel\n",
        "csv_path = os.path.join(log_dir, \"metrics.csv\")\n",
        "metrics_df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Pick best lambda by F1\n",
        "best_idx = metrics_df[\"f1\"].idxmax()\n",
        "best_f1 = metrics_df[\"f1\"].max()\n",
        "best_lambda = metrics_df.loc[best_idx, \"lambda\"]\n",
        "print(f\"Best f1 scores = {best_f1}\")\n",
        "print(f\"Best lambda by f1 = {best_lambda:.3f}\")\n",
        "\n",
        "# Plot all metrics vs. lambda\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(metrics_df[\"lambda\"], metrics_df[\"f1\"])\n",
        "\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"F1 score\")\n",
        "plt.title(\"Metrics vs. F1\")\n",
        "plt.legend()\n",
        "plot_path = os.path.join(log_dir, \"f1_vs_lambda.png\")\n",
        "plt.savefig(plot_path)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 vs scaling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"text.usetex\": True,\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [\"Computer Modern Roman\"],\n",
        "    \"axes.labelsize\": 10,\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 9,\n",
        "    \"xtick.labelsize\": 9,\n",
        "    \"ytick.labelsize\": 9,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_f1_vs_sample_scaling(\n",
        "    best_lambda=0.1,\n",
        "    rho=1.0,\n",
        "    max_iter=200,\n",
        "    tol=1e-4,\n",
        "    threshold=1e-1,\n",
        "    scaling_values=[0.1, 0.5, 1, 1.5, 2, 4, 5, 10, 20],\n",
        "    num_trials=20,\n",
        "    log_dir=\"experiment_scale_logs\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot F1 score and worst-case error vs. sample scaling for different graph types\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # Figsize fits IEEE double column\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(3.5, 6), sharex=False)\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        \"text.usetex\": True,\n",
        "        \"font.family\": \"serif\",\n",
        "        \"font.serif\": [\"Computer Modern Roman\"],\n",
        "        'font.size': 10,\n",
        "        'axes.labelsize': 10,\n",
        "        'axes.titlesize': 10,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'legend.fontsize': 10,\n",
        "    })\n",
        "\n",
        "    markers = {\n",
        "        MatrixType.BUS_33_MODIFIED: \"o\",\n",
        "        MatrixType.WATER_NETWORK: \"^\",\n",
        "        MatrixType.GRID_GRAPH: \"o\",\n",
        "        MatrixType.SMALL_WORLD: \"s\",\n",
        "        MatrixType.SCALE_FREE: \"D\",\n",
        "        MatrixType.ERDOS_RENYI: \"^\"\n",
        "    }\n",
        "    linestyles = {\n",
        "        MatrixType.BUS_33_MODIFIED: \"dashed\",\n",
        "        MatrixType.WATER_NETWORK: \"dashdot\",\n",
        "        MatrixType.GRID_GRAPH: \"dashed\",\n",
        "        MatrixType.SMALL_WORLD: \"dashdot\",\n",
        "        MatrixType.SCALE_FREE: \"dotted\",\n",
        "        MatrixType.ERDOS_RENYI: (0, (3, 1, 1, 1))\n",
        "    }\n",
        "\n",
        "    legend_labels = {\n",
        "    MatrixType.SCALE_FREE: \"Scale Free\",\n",
        "    MatrixType.ERDOS_RENYI: \"Erdős-Rényi\",\n",
        "    MatrixType.SMALL_WORLD: \"Small World\",\n",
        "    MatrixType.GRID_GRAPH: \"Grid Graph\",\n",
        "    MatrixType.BUS_33_MODIFIED: \"IEEE Power Network\",\n",
        "    MatrixType.WATER_NETWORK: \"Water Network\",\n",
        "    }\n",
        "\n",
        "    # Use any of the following lines according to the usecase : top for synthetic and bottom for real-world\n",
        "    # for matrix_type in [MatrixType.ERDOS_RENYI, MatrixType.GRID_GRAPH, MatrixType.SMALL_WORLD, MatrixType.SCALE_FREE]:\n",
        "    for matrix_type in [MatrixType.BUS_33_MODIFIED, MatrixType.WATER_NETWORK]:\n",
        "            f1_means = [] # F1 scores averaged over num_trials experiments keeping parameters constant\n",
        "            err_means = [] # Worst case off diag errors errors averaged over num_trials experiments keeping parameters constant\n",
        "            err_stds = [] # Standard deviations for plotting box errors \n",
        "\n",
        "            B = load_B(matrix_type)\n",
        "            ground_truth_adjacency = (B != 0).astype(int) # Ground truth for F1 metric\n",
        "            mask_offdiag = ~np.eye(len(B), dtype=bool) # To ignore diagonals\n",
        "\n",
        "            for scale in scaling_values:\n",
        "                f1_trials = []\n",
        "                error_trials = []\n",
        "\n",
        "                for _ in range(num_trials):\n",
        "                    S, N = generate_sparse_covariance(B, sample_scaling=scale)\n",
        "                    B_est = admm_precision_matrix(S, best_lambda, rho, max_iter, tol)\n",
        "                    B_est_thresholded = hard_threshold(B_est, threshold)\n",
        "\n",
        "                    pred_adj = (B_est_thresholded != 0).astype(int)\n",
        "\n",
        "                    f1 = f1_score(ground_truth_adjacency[mask_offdiag], pred_adj[mask_offdiag])\n",
        "                    max_error = np.max(np.abs(B_est - B)[mask_offdiag])\n",
        "\n",
        "                    f1_trials.append(f1)\n",
        "                    error_trials.append(max_error)\n",
        "\n",
        "                f1_means.append(np.mean(f1_trials))\n",
        "                err_means.append(np.mean(error_trials))\n",
        "                err_stds.append(np.std(error_trials))\n",
        "\n",
        "                print(f\"{matrix_type.name}, scale={scale}, N={N}, F1={np.mean(f1_trials):.3f}, MaxErrStd={np.std(error_trials):.3f}\")\n",
        "\n",
        "            label = legend_labels[matrix_type]\n",
        "            marker = markers[matrix_type]\n",
        "            linestyle = linestyles[matrix_type]\n",
        "\n",
        "            # Plot F1 without error bars\n",
        "            axs[0].plot(\n",
        "                scaling_values, f1_means,\n",
        "                label=label,\n",
        "                marker=marker,\n",
        "                linestyle=linestyle,\n",
        "                linewidth=2,\n",
        "                markersize=4\n",
        "            )\n",
        "\n",
        "            # Plot max error with error bars\n",
        "            axs[1].errorbar(\n",
        "                scaling_values,\n",
        "                err_means,\n",
        "                yerr=err_stds,\n",
        "                label=label,\n",
        "                marker=marker,\n",
        "                linestyle=linestyle,\n",
        "                linewidth=2,\n",
        "                capsize=4,\n",
        "                elinewidth=1,\n",
        "                capthick=1,\n",
        "                markersize=4\n",
        "            )\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel(r\"$\\tau = N/(d^2 \\log p)$\", fontsize=13)\n",
        "        ax.legend(fontsize=9)\n",
        "        ax.grid(True)\n",
        "\n",
        "    axs[0].set_ylabel(\"Average F-score\", fontsize=13)\n",
        "    axs[1].set_ylabel(r\"$\\|\\widehat{L} - L^*\\|_{\\infty}$\", fontsize=13)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"synthetic_data_scaling_highres.png\", dpi=600)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_f1_vs_sample_scaling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Real world estimates\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "B_bus = load_B(MatrixType.BUS_33_MODIFIED)\n",
        "S_bus, _ = generate_sparse_covariance(B_bus, sample_scaling=4)\n",
        "B_water = load_B(MatrixType.WATER_NETWORK)\n",
        "S_water, _ = generate_sparse_covariance(B_water, sample_scaling=4)\n",
        "\n",
        "lambda_ = 0.1  # Regularization strength\n",
        "rho = 1.0  # ADMM penalty parameter\n",
        "max_iter = 200  # Maximum number of iterations\n",
        "tol = 1e-5  # Convergence tolerance\n",
        "\n",
        "# Run the ADMM algorithm using the generated sample covariance matrix\n",
        "B_estimate_bus = admm_precision_matrix(S_bus, 0.278, rho, max_iter, tol)\n",
        "B_estimate_water = admm_precision_matrix(S_water, 0.175, rho, max_iter, tol)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font_size = 20\n",
        "# Create a new figure\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Subplot 1: True B_bus\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.spy(B_bus)\n",
        "plt.title('(a) True 33 Bus Network', fontsize=font_size)\n",
        "\n",
        "# Subplot 2: Estimated B_bus after thresholding\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.spy(hard_threshold(B_estimate_bus, 0.1))\n",
        "plt.title('(b) Estimated Bus Network', fontsize=font_size)\n",
        "\n",
        "# Subplot 3: True B_water\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.spy(B_water)\n",
        "plt.title('(c) True Water Network', fontsize=font_size)\n",
        "\n",
        "# Subplot 4: Estimated B_water after thresholding\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.spy(hard_threshold(B_estimate_water, 0.1))\n",
        "plt.title('(d) Estimated Water Network', fontsize=font_size)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(3.5, 4), dpi=300)\n",
        "\n",
        "# Font size for subplot titles\n",
        "title_fontsize = 8  # small but readable in IEEE column\n",
        "title_pad = 6       # slight spacing above subplot title\n",
        "\n",
        "axs[0, 0].spy(B_bus)\n",
        "axs[0, 0].set_title('(a) True Power Network ', fontsize=title_fontsize, pad=title_pad)\n",
        "\n",
        "axs[0, 1].spy(hard_threshold(B_estimate_bus, 0.1))\n",
        "axs[0, 1].set_title('(b) Estimated Power Network', fontsize=title_fontsize, pad=title_pad)\n",
        "\n",
        "axs[1, 0].spy(B_water)\n",
        "axs[1, 0].set_title('(c) True Water Network', fontsize=title_fontsize, pad=title_pad)\n",
        "\n",
        "axs[1, 1].spy(hard_threshold(B_estimate_water, 0.1))\n",
        "axs[1, 1].set_title('(d) Estimated Water Network', fontsize=title_fontsize, pad=title_pad)\n",
        "\n",
        "# Reduce space between subplots\n",
        "plt.tight_layout(pad=0.8)  # Adjust if you want even tighter layout\n",
        "\n",
        "# Save as high-res image for IEEE paper\n",
        "plt.savefig(\"ieee_column_subplots.pdf\", bbox_inches='tight')  # or use .png/.eps\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
