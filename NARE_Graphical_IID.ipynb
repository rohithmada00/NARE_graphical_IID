{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs9xYzKTzuD4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.linalg as la\n",
        "from scipy.linalg import solve_sylvester, norm\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 854,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_positive_definite(M, epsilon=1e-1, min_threshold=1e-3):\n",
        "    \"\"\"Ensure M is well-conditioned ; add small value to diagonal if needed\"\"\"\n",
        "    min_eig = np.min(np.linalg.eigvals(M))\n",
        "    \n",
        "    if min_eig < min_threshold:\n",
        "        print(f\"Minimum eigenvalue too small ({min_eig:.2e}), adding {epsilon} to diagonal elements.\")\n",
        "        M += np.eye(M.shape[0]) * (abs(min_eig) + epsilon)\n",
        "    \n",
        "    return M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 855,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_tridiagonal_spd_matrix(\n",
        "        n_dim=10,\n",
        "        smallest_coef=0.1,\n",
        "        largest_coef=0.9,\n",
        "        random_state=None\n",
        "):\n",
        "    \"\"\" \n",
        "    Generate a tridiagonal SPD matrix\n",
        "    \"\"\"\n",
        "\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    diag = [1 for _ in range(n_dim)]\n",
        "    sub_diag = [rng.uniform(low=smallest_coef, high= largest_coef) for _ in range(n_dim-1)]\n",
        "    # sub_diag = [0.7 for _ in range(n_dim-1)]\n",
        "\n",
        "    m = np.zeros((n_dim, n_dim), dtype= float)\n",
        "\n",
        "    # fill diagonal values\n",
        "    for i in range(n_dim):\n",
        "        m[i][i] = diag[i]\n",
        "\n",
        "    # fill sub, sup diagonal values, they are same here to be symmetric\n",
        "    for i in range(n_dim-1):\n",
        "        m[i+1][i] = sub_diag[i] \n",
        "        m[i][i+1] = sub_diag[i]\n",
        "    \n",
        "\n",
        "    return ensure_positive_definite(m)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 856,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum eigenvalue too small (-3.17e-01), adding 0.1 to diagonal elements.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x27d0d1dead0>"
            ]
          },
          "execution_count": 856,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.spy(make_tridiagonal_spd_matrix()) # check if its giving "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 857,
      "metadata": {
        "id": "8tgDmkf5Lg2o"
      },
      "outputs": [],
      "source": [
        "def generate_sparse_covariance(B, sample_scaling=1.0):\n",
        "    \"\"\"\n",
        "    Generate a sparse inverse covariance matrix B, compute its associated covariance matrix E,\n",
        "    and generate samples from a multivariate normal distribution with covariance E.\n",
        "\n",
        "    Parameters:\n",
        "    - n (int): Dimension of the matrix.\n",
        "    - sample_scaling (float): Scaling factor for the number of samples (N = sample_scaling * d^2 log2(n)).\n",
        "    - random_state (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - S (np.ndarray): Sample covariance matrix from the generated samples.\n",
        "    - N (int): Computed number of samples.\n",
        "    \"\"\"\n",
        "    # np.random.seed(random_state)\n",
        "\n",
        "    # Create sparse PSD matrix (B)\n",
        "    # B = make_tridiagonal_spd_matrix(n_dim=n, random_state= random_state)\n",
        "    n = len(B)\n",
        "\n",
        "    # Compute degree d as the maximum number of nonzero entries per row in B (excluding diagonal)\n",
        "    d = np.max(np.sum(B != 0, axis=1)) - 1  # Exclude diagonal elements\n",
        "    print(\"Max degree in B\", d)\n",
        "\n",
        "    # Compute the required number of samples with log \n",
        "    N = int(sample_scaling * ((d*d) * np.log(n)))\n",
        "    # N = max(N, n)  # Ensure N is at least n for stability\n",
        "\n",
        "    # Compute true inverse covariance matrix (Strue)\n",
        "    Strue = np.linalg.matrix_power(B, 2)\n",
        "\n",
        "    # Compute covariance matrix (E)\n",
        "    E = np.linalg.inv(Strue)\n",
        "\n",
        "    # Generate N samples Y ~ N(0, E)\n",
        "    y_samples = la.sqrtm(E).dot(np.random.randn(n, N))\n",
        "\n",
        "    # Calculate sample covariance matrix\n",
        "    S = np.cov(y_samples)\n",
        "\n",
        "    return S, N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 858,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum eigenvalue too small (-1.64e-01), adding 0.1 to diagonal elements.\n",
            "Max degree in B 2\n",
            "Number of samples 9\n",
            "F1 norm 79.71424949059008\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "B = make_tridiagonal_spd_matrix()\n",
        "S, N = generate_sparse_covariance(B)\n",
        "plt.subplot(1,3, 1)\n",
        "plt.spy(B)\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(np.linalg.inv(B@B), cmap = 'gray')\n",
        "plt.title(\"True covariance\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(S, cmap = 'gray')\n",
        "plt.title(\"Sample covariance\")\n",
        "print(\"Number of samples\", N)\n",
        "print(\"F1 norm\", np.linalg.norm(np.linalg.inv(B@B)-S, ord=\"fro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 859,
      "metadata": {
        "id": "tQGJnPihlgjt"
      },
      "outputs": [],
      "source": [
        "def newton_nare(A, B, C, D, X0, tol=1e-13, kmax=30):\n",
        "    \"\"\"\n",
        "    Newton's method for solving the Nonlinear Algebraic Riccati Equation (NARE):\n",
        "    C + XA + DX - XBX = 0\n",
        "    \"\"\"\n",
        "    X = X0.copy()\n",
        "    k = 0\n",
        "    err = 1\n",
        "\n",
        "    while err > tol and k < kmax:\n",
        "        # Compute residual RX = C + XA + DX - XBX\n",
        "        RX = C + X @ A + D @ X - X @ B @ X\n",
        "\n",
        "        # Solve the Sylvester equation (D - XB)H + H(A - BX) = -RX for H\n",
        "        H = solve_sylvester(D - X @ B, A - B @ X, -RX)\n",
        "\n",
        "        # Update X\n",
        "        X = X + H\n",
        "\n",
        "        # Calculate the error; changed from l1 to frobenius\n",
        "        err = norm(H, 1) / norm(X, 1)\n",
        "        # err = norm(H, 'fro') / (1 + norm(X, 'fro'))\n",
        "\n",
        "        # Increment iteration counter\n",
        "        k += 1\n",
        "\n",
        "    if k % 5 == 0:  # Print every 5 iterations\n",
        "        print(f\"Iteration {k}, Error: {err:.2e}\")\n",
        "\n",
        "    # Check if the solution converged\n",
        "    if k == kmax:\n",
        "        print(\"Warning: reached the maximum number of iterations without convergence.\")\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 860,
      "metadata": {
        "id": "sdGMJuRwnPup"
      },
      "outputs": [],
      "source": [
        "# Soft thresholding function\n",
        "def soft_thresholding(x, threshold):\n",
        "    \"\"\"Applies soft-thresholding elementwise.\"\"\"\n",
        "    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 861,
      "metadata": {
        "id": "h2vCOGBFnT5J"
      },
      "outputs": [],
      "source": [
        "# ADMM Algorithm for Elastic-Net Penalized Precision Matrix Estimation\n",
        "def admm_precision_matrix(S, lambda_, rho=1.0, max_iter=100, tol=1e-4):\n",
        "    \"\"\"\n",
        "    ADMM algorithm for precision matrix estimation with elastic-net penalty.\n",
        "    \"\"\"\n",
        "    n = S.shape[0]\n",
        "    Z = np.zeros((n, n))\n",
        "    Lambda = np.zeros((n, n))\n",
        "    I = np.eye(n)  # Identity matrix\n",
        "\n",
        "    # Initial B (can be initialized as identity matrix)\n",
        "    B = np.eye(n)\n",
        "\n",
        "    for k in range(max_iter):\n",
        "        # Step 1: Update B using Newton NARE\n",
        "        # Here, we set up the matrices to solve the NARE: A3 + XA1 + A4X - XA2X = 0\n",
        "        A3 = - 2 * I\n",
        "        A4 = Lambda - rho * Z\n",
        "        A1 = 0 * I\n",
        "        A2 = - (2 * S + rho * I)\n",
        "        X0 = B  # Initial guess for Newton NARE\n",
        "\n",
        "        # Solve for the new B using Newton NARE\n",
        "        B_new = newton_nare(A1, A2, A3, A4, X0)\n",
        "\n",
        "        # Step 2: Update Z elementwise using soft-thresholding\n",
        "        Z_new = soft_thresholding(rho * B_new + Lambda, lambda_)\n",
        "        Z_new = Z_new / rho\n",
        "\n",
        "        # Step 3: Update Lambda (Lagrange multiplier)\n",
        "        Lambda_new = Lambda + rho * (B_new - Z_new)\n",
        "\n",
        "        print(f\"ADMM update loss: \", np.linalg.norm(B_new - B, ord='fro') )\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(B_new - B, ord='fro') < tol:\n",
        "            print(f\"ADMM Converged after {k+1} iterations.\")\n",
        "            break\n",
        "        elif k == max_iter-1 :\n",
        "            print(f\"ADMM failed to converge after {k+1} iterations.\")\n",
        "\n",
        "        # Update for the next iteration\n",
        "        B, Z, Lambda = B_new, Z_new, Lambda_new      \n",
        "\n",
        "    return B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 862,
      "metadata": {
        "id": "U0IvvFLPs1u-"
      },
      "outputs": [],
      "source": [
        "#Thresholding B_estimate\n",
        "def hard_threshold(B_estimate,threshold):\n",
        "  return np.where(np.abs(B_estimate) > threshold, B_estimate, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 863,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum eigenvalue too small (-2.52e-01), adding 0.1 to diagonal elements.\n"
          ]
        }
      ],
      "source": [
        "B = make_tridiagonal_spd_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 864,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max degree in B 2\n",
            "ADMM update loss:  1.4546240271798738\n",
            "ADMM update loss:  1.1030504166689985\n",
            "ADMM update loss:  1.030704911456444\n",
            "Iteration 5, Error: 1.06e-14\n",
            "ADMM update loss:  0.7506042367545458\n",
            "Iteration 5, Error: 3.51e-15\n",
            "ADMM update loss:  0.5675819029279452\n",
            "Iteration 5, Error: 2.95e-15\n",
            "ADMM update loss:  0.44929399966246786\n",
            "Iteration 5, Error: 2.35e-15\n",
            "ADMM update loss:  0.36389903886779595\n",
            "Iteration 5, Error: 2.52e-15\n",
            "ADMM update loss:  0.30232119368135857\n",
            "Iteration 5, Error: 2.71e-15\n",
            "ADMM update loss:  0.2565252741951338\n",
            "Iteration 5, Error: 3.37e-15\n",
            "ADMM update loss:  0.21972079052792787\n",
            "Iteration 5, Error: 2.71e-15\n",
            "ADMM update loss:  0.19038168619233686\n",
            "Iteration 5, Error: 2.81e-15\n",
            "ADMM update loss:  0.16645219099621944\n",
            "Iteration 5, Error: 2.07e-15\n",
            "ADMM update loss:  0.1467802877483828\n",
            "ADMM update loss:  0.13031534128797065\n",
            "ADMM update loss:  0.11640019501113624\n",
            "ADMM update loss:  0.10453320297166492\n",
            "ADMM update loss:  0.09432297446725342\n",
            "ADMM update loss:  0.08546754506536433\n",
            "ADMM update loss:  0.07773176175097807\n",
            "ADMM update loss:  0.0709304429792781\n",
            "ADMM update loss:  0.06491596549018672\n",
            "ADMM update loss:  0.05877463675165884\n",
            "ADMM update loss:  0.05384071252156405\n",
            "ADMM update loss:  0.04942260717160416\n",
            "ADMM update loss:  0.04551271291542696\n",
            "ADMM update loss:  0.04200445204708813\n",
            "ADMM update loss:  0.038842700287895035\n",
            "ADMM update loss:  0.03598032839013146\n",
            "ADMM update loss:  0.033383042519187646\n",
            "ADMM update loss:  0.031010099890993178\n",
            "ADMM update loss:  0.028837245718336683\n",
            "ADMM update loss:  0.026842579759301797\n",
            "ADMM update loss:  0.025007412175716823\n",
            "ADMM update loss:  0.023315640214847198\n",
            "ADMM update loss:  0.021753299668661956\n",
            "ADMM update loss:  0.020308211322081667\n",
            "ADMM update loss:  0.018969692662526086\n",
            "ADMM update loss:  0.017728322056472314\n",
            "ADMM update loss:  0.016575746599843705\n",
            "ADMM update loss:  0.015504525548495119\n",
            "ADMM update loss:  0.014508002068288122\n",
            "ADMM update loss:  0.013580197319613066\n",
            "ADMM update loss:  0.012715722225441298\n",
            "ADMM update loss:  0.011909703396612384\n",
            "ADMM update loss:  0.011157720532651945\n",
            "ADMM update loss:  0.010455753221104678\n",
            "ADMM update loss:  0.009800135492018754\n",
            "ADMM update loss:  0.009187516805939658\n",
            "ADMM update loss:  0.00861482840220341\n",
            "ADMM update loss:  0.008079254131824339\n",
            "ADMM update loss:  0.007578205058785391\n",
            "ADMM update loss:  0.007109297242552278\n",
            "ADMM update loss:  0.006670332219186381\n",
            "ADMM update loss:  0.006257205269348813\n",
            "ADMM update loss:  0.0058703376986702525\n",
            "ADMM update loss:  0.005508141804144699\n",
            "ADMM update loss:  0.005169042116332954\n",
            "ADMM update loss:  0.004851418664951738\n",
            "ADMM update loss:  0.0045537339153346665\n",
            "ADMM update loss:  0.004274654955937855\n",
            "ADMM update loss:  0.004012977932727449\n",
            "ADMM update loss:  0.0037675866101745414\n",
            "ADMM update loss:  0.003537438363632591\n",
            "ADMM update loss:  0.0033215587215269806\n",
            "ADMM update loss:  0.00311903779924732\n",
            "ADMM update loss:  0.0029290265603254045\n",
            "ADMM update loss:  0.0027507327181898814\n",
            "ADMM update loss:  0.0025834166328403733\n",
            "ADMM update loss:  0.0024263874620216717\n",
            "ADMM update loss:  0.0022789996435662813\n",
            "ADMM update loss:  0.0021406496905814394\n",
            "ADMM update loss:  0.002010773257607439\n",
            "ADMM update loss:  0.0018888424410929503\n",
            "ADMM update loss:  0.001774363286831876\n",
            "ADMM update loss:  0.0016668734839442856\n",
            "ADMM update loss:  0.0015659402288429908\n",
            "ADMM update loss:  0.0014711582451671543\n",
            "ADMM update loss:  0.0013821479471102338\n",
            "ADMM update loss:  0.0012985537348815751\n",
            "ADMM update loss:  0.0012200424119051935\n",
            "ADMM update loss:  0.0011463017142746368\n",
            "ADMM update loss:  0.0010770389436695858\n",
            "ADMM update loss:  0.0010119796957346425\n",
            "ADMM update loss:  0.0009508666765215772\n",
            "ADMM update loss:  0.0008934586003052638\n",
            "ADMM update loss:  0.0008395291626084853\n",
            "ADMM update loss:  0.0007888660828235992\n",
            "ADMM update loss:  0.0007412702112331176\n",
            "ADMM update loss:  0.0006965546958044992\n",
            "ADMM update loss:  0.0006545442043132221\n",
            "ADMM update loss:  0.0006150741979102076\n",
            "ADMM update loss:  0.0005779902524016403\n",
            "ADMM update loss:  0.0005431474239247609\n",
            "ADMM update loss:  0.0005104096558778796\n",
            "ADMM update loss:  0.0004796492242657749\n",
            "ADMM update loss:  0.00045074621881300105\n",
            "ADMM update loss:  0.00042358805739813\n",
            "ADMM update loss:  0.0003980690315444413\n",
            "ADMM update loss:  0.0003740898808943455\n",
            "ADMM update loss:  0.00035155739471096547\n",
            "ADMM failed to converge after 100 iterations.\n",
            "Estimated Precision Matrix (B estimate):\n",
            "[[ 2.01796831e+00  1.24338049e-01 -4.26833503e-01 -6.16126148e-01\n",
            "  -7.62985017e-07  8.34165942e-01  3.93503465e-01 -8.96849985e-02\n",
            "   1.45567010e-06  4.70697319e-01]\n",
            " [ 6.34225210e-02  1.76666825e+00  9.78811937e-01 -2.13915954e-01\n",
            "   6.33230553e-01 -6.64312036e-02  1.76211324e-01  5.60365557e-01\n",
            "  -5.45132748e-06  2.40259766e-01]\n",
            " [-4.79727488e-01  9.43782715e-01  1.87148255e+00  1.44894933e+00\n",
            "  -9.34124364e-02  2.30083609e-01  2.78814048e-02 -8.27110131e-03\n",
            "   4.82158342e-01  7.69184358e-06]\n",
            " [-6.41511109e-01 -2.67118567e-01  1.43372862e+00  2.36742920e+00\n",
            "   1.54768789e-07  3.61721953e-01 -7.37003000e-02 -6.00354737e-01\n",
            "   6.11083202e-02 -4.33939564e-01]\n",
            " [ 3.28328491e-06  6.65025638e-01 -1.06244672e-01 -1.09208008e-06\n",
            "   4.22765089e+00 -5.26173756e-06 -1.02986751e-02  4.49733487e-01\n",
            "  -1.46627509e+00 -3.95285744e-01]\n",
            " [ 9.34812303e-01 -2.69156886e-02  1.92977071e-01  2.61917891e-01\n",
            "   3.89693166e-02  2.65222384e+00  1.01028754e+00 -5.64550425e-01\n",
            "   7.13558880e-07  6.41414330e-01]\n",
            " [ 3.94249224e-01  1.93878554e-01  1.02974969e-02 -1.12138470e-01\n",
            "   5.26686962e-06  9.51125451e-01  2.06606902e+00  9.45783444e-01\n",
            "  -6.96238334e-01  1.46498760e-02]\n",
            " [-1.10645397e-01  5.94887933e-01  6.11787694e-07 -6.07197410e-01\n",
            "   3.69682595e-01 -6.07006174e-01  9.72652091e-01  1.93755847e+00\n",
            "   2.01555110e-01  4.18007616e-02]\n",
            " [-3.74092380e-06 -4.55782743e-07  4.53183878e-01 -8.76415010e-07\n",
            "  -1.49835854e+00  6.59987831e-06 -6.23401119e-01  3.22783598e-01\n",
            "   3.99810509e+00  1.38892077e+00]\n",
            " [ 4.45316846e-01  2.57899928e-01  8.33410097e-06 -4.09228100e-01\n",
            "  -2.51358117e-01  5.66442930e-01 -3.41919473e-06  5.61115649e-02\n",
            "   1.23695929e+00  2.22064267e+00]]\n"
          ]
        }
      ],
      "source": [
        "S, N = generate_sparse_covariance(B, sample_scaling=1.0)\n",
        "# Parameters for the elastic-net penalty and ADMM algorithm\n",
        "lambda_ = 0.1  # Regularization strength\n",
        "alpha = 1  # Mixing parameter (0 = Ridge, 1 = Lasso)\n",
        "rho = 1.0  # ADMM penalty parameter\n",
        "max_iter = 100  # Maximum number of iterations\n",
        "tol = 1e-4  # Convergence tolerance\n",
        "\n",
        "# Run the ADMM algorithm using the generated sample covariance matrix\n",
        "B_estimate = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "\n",
        "print(\"Estimated Precision Matrix (B estimate):\")\n",
        "print(B_estimate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 865,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'B estimate - 0.3 tres')"
            ]
          },
          "execution_count": 865,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(1,3, 1)\n",
        "plt.imshow(B, cmap= \"gray\")\n",
        "plt.title(\"Btrue\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(hard_threshold(B_estimate, 0.2), cmap= \"gray\")\n",
        "plt.title(\"B estimate - 0.2 tres\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(hard_threshold(B_estimate, 0.4), cmap= \"gray\")\n",
        "plt.tight_layout()\n",
        "plt.title(\"B estimate - 0.3 tres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 866,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_metrics_vs_lambda(lambda_values, n = 10, sample_scaling = 1.0,  rho=1.0, max_iter=100, tol=1e-4, threshold=1e-4, log_dir=\"experiment_logs\"):    \n",
        "    \"\"\"\n",
        "    Evaluate Frobenius norm, KL divergence, MCC, Sensitivity, and Specificity\n",
        "    of the estimated precision matrix at various lambda values.\n",
        "    \"\"\"\n",
        "    \n",
        "    B = make_tridiagonal_spd_matrix(n_dim= n)\n",
        "    S, N = generate_sparse_covariance(B, sample_scaling= sample_scaling)\n",
        "    ground_truth_adjacency = (B != 0).astype(int).flatten()\n",
        "    logdet_B = np.log(np.linalg.det(B))\n",
        "\n",
        "    print(\"Number of samples:\", N)\n",
        "    print(\"Minimum eigenvalue:\", np.min(np.linalg.eigvals(B)))\n",
        "\n",
        "    metrics = {\n",
        "        \"lambda\": [],\n",
        "        \"Fnorm\": [],\n",
        "        \"KL\": [],\n",
        "        \"MCC\": [],\n",
        "        \"sensitivity\": [],\n",
        "        \"specificity\": [],\n",
        "        \"f1\": [], \n",
        "        \"plot_paths\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    for lambda_ in lambda_values:\n",
        "        # Compute estimated precision matrix\n",
        "        B_est  = admm_precision_matrix(S, lambda_, rho, max_iter, tol)\n",
        "        \n",
        "        # Apply thresholding\n",
        "        B_est_thresholded  = hard_threshold(B_est, threshold)\n",
        "\n",
        "        # Plot sparsity patterns and save them\n",
        "        plt.figure(figsize=(6, 12))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.spy(B)\n",
        "        plt.title('B matrix', fontsize=16)\n",
        "\n",
        "        # Placeholder for estimated matrix\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.spy(B_est_thresholded)\n",
        "        plt.title('B_hat (Estimated)', fontsize=16)\n",
        "\n",
        "        plot_path = os.path.join(log_dir, f\"sparsity_patterns_lambda_{lambda_:.3f}.png\")\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "        \n",
        "        metrics[\"plot_paths\"].append(plot_path)\n",
        "\n",
        "        # Fnorm_val\n",
        "        Fnorm_val = np.linalg.norm(B - B_est, ord='fro')\n",
        "\n",
        "        # KL divergence\n",
        "        try:\n",
        "            inv_Best = np.linalg.inv(B_est)\n",
        "            logdet_Best = np.log(np.linalg.det(B_est))\n",
        "            trace_term = np.trace(inv_Best @ B)\n",
        "            KL_val = -logdet_Best + trace_term + logdet_B - n\n",
        "        except np.linalg.LinAlgError:\n",
        "            # If B_est is singular, define KL as + or some large number\n",
        "            KL_val = np.inf\n",
        "        \n",
        "        predicted_adjacency = (B_est_thresholded != 0).astype(int).flatten()\n",
        "        cm = confusion_matrix(ground_truth_adjacency, predicted_adjacency, labels=[0,1])\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "        # MCC = (TP*TN - FP*FN) / sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) )\n",
        "        # We'll do a safe-check:\n",
        "        denom = (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)\n",
        "        if denom == 0:\n",
        "            MCC_val = 0.0\n",
        "        else:\n",
        "            MCC_val = ((TP*TN) - (FP*FN)) / np.sqrt(denom)\n",
        "        \n",
        "        # Sensitivity = TP / (TP + FN)  [recall]\n",
        "        sensitivity_val = TP / (TP + FN) if (TP+FN) > 0 else 0.0\n",
        "        # Specificity = TN / (TN + FP)\n",
        "        specificity_val = TN / (TN + FP) if (TN+FP) > 0 else 0.0\n",
        "        # F1 score\n",
        "        f1_val = f1_score(ground_truth_adjacency, predicted_adjacency)\n",
        "\n",
        "        metrics[\"lambda\"].append(lambda_)\n",
        "        metrics[\"Fnorm\"].append(Fnorm_val)\n",
        "        metrics[\"KL\"].append(KL_val)\n",
        "        metrics[\"MCC\"].append(MCC_val)\n",
        "        metrics[\"sensitivity\"].append(sensitivity_val)\n",
        "        metrics[\"specificity\"].append(specificity_val)\n",
        "        metrics[\"f1\"].append(f1_val)\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V2nbZQbUthdT",
        "outputId": "b5159b66-0f83-4b92-92f9-3cf7caa3c334"
      },
      "outputs": [],
      "source": [
        "# Updated main loop\n",
        "n = 51\n",
        "sample_scaling = 1.0\n",
        "\n",
        "log_dir = f\"experiment_logs/n_{n}_scale_{sample_scaling}\"\n",
        "# Create a directory to save logs if it doesnt exist\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# params\n",
        "args = {\n",
        "    \"lambda_values\": np.linspace(0.1,1.2, 20).tolist(),\n",
        "    \"n\": n,\n",
        "    \"sample_scaling\": sample_scaling,\n",
        "    \"rho\": 3.0,\n",
        "    \"max_iter\": 500,\n",
        "    \"tol\": 1e-4,\n",
        "    \"threshold\": 1e-3,\n",
        "    \"log_dir\": log_dir\n",
        "}\n",
        "print(f\"Evaluating metrics for {args}\")\n",
        "\n",
        "# Save args to a JSON file (for reproducibility)\n",
        "json_path = os.path.join(log_dir, \"params.json\")\n",
        "with open(json_path, \"w\") as json_file:\n",
        "    json.dump(args, json_file, indent=4)\n",
        "\n",
        "# Call our updated evaluate_metrics_vs_lambda\n",
        "metrics = evaluate_metrics_vs_lambda(**args)\n",
        "\n",
        "# Convert metrics to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Save metrics to CSV or Excel\n",
        "csv_path = os.path.join(log_dir, \"metrics.csv\")\n",
        "metrics_df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Pick best lambda by F1\n",
        "best_idx = metrics_df[\"f1\"].idxmax()\n",
        "best_lambda = metrics_df.loc[best_idx, \"lambda\"]\n",
        "print(f\"Best lambda by F1 = {best_lambda:.3f}\")\n",
        "\n",
        "# Plot all metrics vs. lambda\n",
        "plt.figure(figsize=(8, 6))\n",
        "for metric in [\"f1\"]:\n",
        "    plt.plot(metrics_df[\"lambda\"], metrics_df[metric], marker=\"o\", label=metric)\n",
        "\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Metrics vs. Lambda\")\n",
        "plt.legend()\n",
        "plot_path = os.path.join(log_dir, \"metrics_vs_lambda.png\")\n",
        "plt.savefig(plot_path)\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 vs sample scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "\n",
        "def plot_f1_vs_sample_scaling(\n",
        "    n=51,\n",
        "    alpha=0.92,\n",
        "    best_lambda=1.2,\n",
        "    rho=3.0,\n",
        "    max_iter=500,\n",
        "    tol=1e-4,\n",
        "    threshold=1e-3,\n",
        "    scaling_values=None,\n",
        "    log_dir=\"experiment_scale_logs\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Fix parameters (n, alpha, best_lambda, etc.) and update sample_scaling from\n",
        "    1..20 to see how F1 improves with more samples.\n",
        "    \"\"\"\n",
        "    if scaling_values is None:\n",
        "        # By default, range from 1 to 20 inclusive\n",
        "        scaling_values = np.arange(1, 21)\n",
        "\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    f1_scores = []\n",
        "\n",
        "    for scale in scaling_values:\n",
        "        # Generate data with the current scale\n",
        "        B, S, N = generate_sparse_covariance(\n",
        "            n=n,\n",
        "            sample_scaling=scale,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        # Estimate precision matrix using the best param config\n",
        "        B_est = admm_precision_matrix(S, best_lambda, rho, max_iter, tol)\n",
        "        \n",
        "        # Threshold the estimate\n",
        "        B_est_thresholded = hard_threshold(B_est, threshold)\n",
        "\n",
        "        # Compute adjacency-based F1\n",
        "        ground_truth = (B != 0).astype(int).ravel()\n",
        "        predicted = (B_est_thresholded != 0).astype(int).ravel()\n",
        "        f1_val = f1_score(ground_truth, predicted, zero_division=0)\n",
        "\n",
        "        f1_scores.append(f1_val)\n",
        "\n",
        "        print(f\"scale={scale}, #samples={N}, F1={f1_val:.3f}\")\n",
        "\n",
        "    # Convert to DataFrame for convenience\n",
        "    df = pd.DataFrame({\n",
        "        \"sample_scaling\": scaling_values,\n",
        "        \"F1\": f1_scores\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_path = os.path.join(log_dir, f\"f1_vs_scaling_{n}.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(scaling_values, f1_scores, marker=\"o\")\n",
        "    plt.xlabel(\"N/(d^2log(n))\")\n",
        "    plt.ylabel(\"F1 Score\")\n",
        "    plt.title(f\"F1 vs. Sample Scaling (n={n}, alpha={alpha}, lambda={best_lambda})\")\n",
        "    plt.grid(True)\n",
        "    plot_path = os.path.join(log_dir, f\"f1_vs_scaling_{n}.png\")\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_f1_vs_sample_scaling(\n",
        "        n=50,\n",
        "        alpha=0.98,\n",
        "        best_lambda= 0.1,  \n",
        "        rho=9.0,\n",
        "        max_iter=500,\n",
        "        tol=1e-4,\n",
        "        threshold=1e-3,\n",
        "        scaling_values=np.linspace(1, 6, 30), \n",
        "        log_dir=\"f1_scale_experiment\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
